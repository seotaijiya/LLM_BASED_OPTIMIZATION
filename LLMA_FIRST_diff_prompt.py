from llama_cpp import Llama

import numpy as np
import time
import itertools
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils import data
import torch.optim as optim

#import seaborn as sns


from torch.utils.data import Dataset
from torch.utils.data import DataLoader

np.set_printoptions(precision=3)


## Generate location of D2D users and CUE
def loc_init(Size_area, Dist_TX_RX, Num_D2D, Num_Ch):
    tx_loc = Size_area * (np.random.rand(Num_D2D, 2) - 0.5)
    rx_loc = np.zeros((Num_D2D + 1, 2))
    for i in range(Num_D2D):
        temp_chan = Feasible_Loc_Init(tx_loc[i, :], Size_area, Dist_TX_RX)
        rx_loc[i, :] = temp_chan
    tx_loc_CUE = Size_area * (np.random.rand(Num_Ch, 2) - 0.5)

    return rx_loc, tx_loc, tx_loc_CUE


## Check the feasibililty of generated location
def Feasible_Loc_Init(Cur_loc, Size_area, Dist_TX_RX):
    temp_dist = 2 * Dist_TX_RX * (np.random.rand(1, 2) - 0.5)
    temp_chan = Cur_loc + temp_dist
    while (np.max(abs(temp_chan)) > Size_area / 2) | (np.linalg.norm(temp_dist) > Dist_TX_RX):
        temp_dist = 2 * Dist_TX_RX * (np.random.rand(1, 2) - 0.5)
        temp_chan = Cur_loc + temp_dist
    return temp_chan


## Generate sample data for channel
def ch_gen(Size_area, D2D_dist, Num_D2D, Num_Ch, Num_samples, PL_alpha=38., PL_const=34.5):
      ch_w_fading = []
      rx_loc_mat = []
      tx_loc_mat = []
      CUE_loc_mat = []

      ch_w_fading = []

      ## Perform initialization just once and the rest channel is generated by moving users
      rx_loc, tx_loc, tx_loc_CUE = loc_init(Size_area, D2D_dist, Num_D2D, Num_Ch)

      ## Calculate the
      for i in range(Num_samples):

            rx_loc, tx_loc, tx_loc_CUE = loc_init(Size_area, D2D_dist, Num_D2D, Num_Ch)

            ch_w_temp_band = []
            for j in range(Num_Ch):
                  tx_loc_with_CUE = np.vstack((tx_loc, tx_loc_CUE[j]))
                  ## generate distance_vector
                  dist_vec = rx_loc.reshape(Num_D2D + 1, 1, 2) - tx_loc_with_CUE
                  dist_vec = np.linalg.norm(dist_vec, axis=2)
                  dist_vec = np.maximum(dist_vec, 3)

                  # find path loss // shadowing is not considered
                  pu_ch_gain_db = - PL_const - PL_alpha * np.log10(dist_vec)
                  pu_ch_gain = 10 ** (pu_ch_gain_db / 10)

                  multi_fading = 0.5 * np.random.randn(Num_D2D + 1, Num_D2D + 1) ** 2 + 0.5 * np.random.randn(
                        Num_D2D + 1,
                        Num_D2D + 1) ** 2
                  final_ch = np.maximum(pu_ch_gain * multi_fading, np.exp(-30))
                  ch_w_temp_band.append(np.transpose(final_ch))

            ch_w_fading.append(ch_w_temp_band)
            rx_loc_mat.append(rx_loc)
            tx_loc_mat.append(tx_loc)
            CUE_loc_mat.append(tx_loc_CUE)

      return np.array(ch_w_fading), np.array(rx_loc_mat), np.array(tx_loc_mat), np.array(CUE_loc_mat)


## Simulation setting for sample channel data

Size_area = 50.0
D2D_dist = 10
Num_user = 2
Num_channel = 1
num_samples_tr = 30


def cal_rate_NP(channel, tx_power_in, tx_max, noise, DUE_thr, I_thr, P_c):
      num_sample = channel.shape[0]
      num_channel = channel.shape[1]
      num_D2D_user = channel.shape[2] - 1

      ## Initialization
      tot_SE = 0
      tot_EE = 0
      tot_cap_CUE_vio = 0
      tot_cap_DUE_vio = 0
      tot_cap_CUE_vio_num = 0.001
      tot_cap_DUE_vio_num = 0.001
      DUE_violation = 0
      CUE_violation = 0
      tot_success_prob = 0

      ## Append tx power and CUE tx power
      tx_power = np.hstack((tx_power_in, 0 * np.ones((tx_power_in.shape[0], 1, num_channel))))

      for i in range(num_sample):
            cur_cap = 0
            DUE_mask = 1
            CUE_mask = 1

            for j in range(num_channel):
                  cur_ch = channel[i][j]
                  cur_power = tx_power[i, :, j]
                  cur_power = np.array([cur_power])
                  cur_ch_cap = cal_RATE_one_sample_one_channel(cur_ch, cur_power, noise)
                  inter = cal_CUE_INTER_one_sample_one_channel(cur_ch, cur_power)
                  cur_cap = cur_cap + cur_ch_cap[0]
                  CUE_mask = CUE_mask * (inter[0, num_D2D_user] <= I_thr)

            for j in range(num_D2D_user):
                  DUE_mask = DUE_mask * (cur_cap[j] >= DUE_thr)

            D2D_SE_sum = np.sum(cur_cap[:-1]) * CUE_mask * DUE_mask
            D2D_EE_sum = np.sum(cur_cap[:-1] / (np.sum(tx_power_in[i], axis=1) + P_c)) * CUE_mask * DUE_mask

            if CUE_mask == 0:
                  CUE_violation = CUE_violation + 1

            if DUE_mask == 0:
                  DUE_violation = DUE_violation + 1

            tot_SE = tot_SE + D2D_SE_sum
            tot_EE = tot_EE + D2D_EE_sum

      tot_SE = tot_SE / num_D2D_user / num_sample
      tot_EE = tot_EE / num_D2D_user / num_sample
      PRO_DUE_vio = DUE_violation / (num_sample)
      PRO_CUE_vio = CUE_violation / (num_sample)

      return tot_SE, tot_EE, PRO_CUE_vio, PRO_DUE_vio



ch_mat, rx_mat, tx_mat, CUE_mat = ch_gen(Size_area, D2D_dist, Num_user, Num_channel, int(10**4))
tx_power_in = 10**2.0*np.ones((ch_mat.shape[0], 2, 1))




def all_possible_tx_power(num_channel, num_user, granuty):

    items = [np.arange(granuty)] * num_user * num_channel
    temp_power = list(itertools.product(*items))
    temp_power = np.reshape(temp_power, (-1, num_user, num_channel))

    power_check = np.sum(temp_power, axis=2)
    flag = (power_check / (granuty - 1) <= 1).astype(int)
    flag = (np.sum(flag, axis=1) / num_user == 1).astype(int)
    flag = np.reshape(flag, (-1, 1))
    temp_power_1 = np.reshape(temp_power, (-1, num_user * num_channel))
    temp_power = temp_power_1 * flag
    power = np.reshape(temp_power, (-1, num_user, num_channel)) / (granuty - 1)

    power_mat = []
    for i in range(power.shape[0]):
        sum_val = np.sum(power[i])
        if sum_val != 0:
            power_mat.append(power[i])

    return np.array(power_mat)


def optimal_power(channel, tx_max, noise, DUE_thr, I_thr, P_c, tx_power_set, opt="SE"):
      num_channel = channel.shape[1]
      num_D2D_user = channel.shape[2] - 1
      num_samples = channel.shape[0]
      tot_SE = 0
      power_mat_SE = []
      chan_infea_mat = []

      for i in range(num_samples):
            cur_cap = 0
            DUE_mask = 1
            CUE_mask = 1
            tx_power = tx_max * np.hstack((tx_power_set, 0*np.ones((tx_power_set.shape[0], 1, num_channel))))

            for j in range(num_channel):
                  cur_ch = channel[i][j]
                  cur_ch_cap = cal_RATE_one_sample_one_channel(cur_ch, tx_power[:, :, j], noise)
                  inter = cal_CUE_INTER_one_sample_one_channel(cur_ch, tx_power[:, :, j])
                  cur_cap = cur_cap + cur_ch_cap
                  CUE_mask = CUE_mask * (inter[:, num_D2D_user] < I_thr)

            for j in range(num_D2D_user):
                  DUE_mask = DUE_mask * (cur_cap[:, j] > DUE_thr)

            CUE_mask = np.expand_dims(CUE_mask, -1)
            DUE_mask = np.expand_dims(DUE_mask, -1)

            sum_D2D_SE_temp = np.expand_dims(np.sum(cur_cap[:, :-1], axis=1), -1)
            sum_D2D_EE_temp = np.expand_dims(
                  np.sum(cur_cap[:, :-1] / (np.sum(tx_power[:, :-1, :], axis=2) + P_c), axis=1), -1)

            D2D_SE_sum = sum_D2D_SE_temp * DUE_mask
            D2D_EE_sum = sum_D2D_EE_temp * DUE_mask

            if opt == "SE":
                  arg_max_val = np.argmax(D2D_SE_sum)
            else:
                  arg_max_val = np.argmax(D2D_EE_sum)

            max_SE = np.max(D2D_SE_sum)

            found_tx_val = tx_power[arg_max_val][:-1]

            power_mat_SE.append(found_tx_val)

            ## Collect the infeasible channels
            if max_SE == 0:
                  chan_infea_mat.append(channel[i])

      power_mat_SE = np.array(power_mat_SE)

      tot_SE, tot_EE, PRO_CUE_vio, PRO_DUE_vio = cal_rate_NP(channel, power_mat_SE, tx_max, noise, DUE_thr, I_thr, P_c)

      return tot_SE, tot_EE, PRO_CUE_vio, PRO_DUE_vio, np.array(chan_infea_mat)


## Calculate data rate for single channel, single sample
def cal_RATE_one_sample_one_channel(channel, tx_power, noise):
    diag_ch = np.diag(channel)
    inter_ch = channel-np.diag(diag_ch)
    tot_ch = np.multiply(channel, np.expand_dims(tx_power, -1))
    int_ch = np.multiply(inter_ch, np.expand_dims(tx_power, -1))
    sig_ch = np.sum(tot_ch-int_ch, axis=1)
    int_ch = np.sum(int_ch, axis=1)
    SINR_val = np.divide(sig_ch, int_ch+noise)
    cap_val = np.log2(1.0+SINR_val)
    return cap_val


def cal_CUE_INTER_one_sample_one_channel(channel, tx_power):
    diag_ch = np.diag(channel)
    inter_ch = channel-np.diag(diag_ch)
    int_ch = np.multiply(inter_ch, np.expand_dims(tx_power, -1))
    int_ch = np.sum(int_ch, axis=1)
    return int_ch




def optimal_power_w_chan(channel, tx_max, noise, DUE_thr, I_thr, P_c, tx_power_set, opt="SE"):
      num_channel = channel.shape[1]
      num_D2D_user = channel.shape[2] - 1
      num_samples = channel.shape[0]
      tot_SE = 0
      power_mat_SE = []
      chan_infea_mat = []

      for i in range(num_samples):
            cur_cap = 0
            DUE_mask = 1
            CUE_mask = 1
            tx_power = tx_max * np.hstack((tx_power_set, 0*np.ones((tx_power_set.shape[0], 1, num_channel))))

            for j in range(num_channel):
                  cur_ch = channel[i][j]
                  cur_ch_cap = cal_RATE_one_sample_one_channel(cur_ch, tx_power[:, :, j], noise)
                  inter = cal_CUE_INTER_one_sample_one_channel(cur_ch, tx_power[:, :, j])
                  cur_cap = cur_cap + cur_ch_cap
                  CUE_mask = CUE_mask * (inter[:, num_D2D_user] < I_thr)

            for j in range(num_D2D_user):
                  DUE_mask = DUE_mask * (cur_cap[:, j] > DUE_thr)

            CUE_mask = np.expand_dims(CUE_mask, -1)
            DUE_mask = np.expand_dims(DUE_mask, -1)

            sum_D2D_SE_temp = np.expand_dims(np.sum(cur_cap[:, :-1], axis=1), -1)
            sum_D2D_EE_temp = np.expand_dims(
                  np.sum(cur_cap[:, :-1] / (np.sum(tx_power[:, :-1, :], axis=2) + P_c), axis=1), -1)

            D2D_SE_sum = sum_D2D_SE_temp
            D2D_EE_sum = sum_D2D_EE_temp

            if opt == "SE":
                  arg_max_val = np.argmax(D2D_SE_sum)
            else:
                  arg_max_val = np.argmax(D2D_EE_sum)

            max_SE = np.max(D2D_SE_sum)

            found_tx_val = tx_power[arg_max_val][:-1]

            power_mat_SE.append(found_tx_val)

            ## Collect the infeasible channels
            if max_SE == 0:
                  chan_infea_mat.append(channel[i])

      power_mat_SE = np.array(power_mat_SE)
      tot_SE, tot_EE, PRO_CUE_vio, PRO_DUE_vio = cal_rate_NP(channel, power_mat_SE, tx_max, noise, DUE_thr, I_thr, P_c)


      return tot_SE, tot_EE, PRO_CUE_vio, PRO_DUE_vio, np.array(chan_infea_mat), np.array(power_mat_SE), np.array(
            channel)


def cal_SE_EE(channel, tx_max, noise, DUE_thr, I_thr, P_c, tx_power_mat, opt="SE"):
    num_channel = 1
    num_D2D_user = channel.shape[0] - 1
    tot_SE = 0

    cur_cap = 0
    DUE_mask = 1
    CUE_mask = 1

    tx_power = np.vstack((tx_power_mat, 0 * np.ones((1, 1))))
    tx_power = np.expand_dims(tx_power, 0)

    cur_ch = channel
    cur_ch_cap = cal_RATE_one_sample_one_channel(cur_ch, tx_power[:, :, 0], noise)
    cur_cap = cur_cap + cur_ch_cap


    sum_D2D_SE_temp = np.sum(cur_cap[0,:-1])
    sum_D2D_EE_temp = np.sum(cur_cap[0,:-1] / (tx_power[0,:-1, 0] + P_c))

    D2D_SE_sum = sum_D2D_SE_temp
    D2D_EE_sum = sum_D2D_EE_temp

    return D2D_SE_sum, D2D_EE_sum



np.random.seed(0)

Num_power_level = 100
tx_power_set = all_possible_tx_power(Num_channel, Num_user, Num_power_level - 1)

Size_area = 20
D2D_dist = 15
tx_max = 10**2.0

DUE_thr = 4.0
I_thr = 10**(-55.0/10)
P_c = 2*10**2.0
BW = 1e7
noise = BW*10**-17.4

llm = Llama(
      #model_path="./models/codellama-7b.Q5_K_M.gguf",
      #model_path="./models/codellama-7b.Q4_K_M.gguf",
      model_path="./models/llama-2-13b.Q5_K_M.gguf",
      #n_gpu_layers=-1, # Uncomment to use GPU acceleration
      # seed=1337, # Uncomment to set a specific seed
      n_ctx=26200,
      verbose=False # Uncomment to increase the context window
)

query_text = """
Take a deep breath and work on this problem step-by-step. You are a mathematical tool to predict some model. Your job is to predict B for given A. The following is the dataset that you can use for the prediction.
If A is 59.6, 73.2, 59.8, 63.6, then B is 100, 100.
If A is 71.0, 59.8, 61.9, 73.7, then B is 0, 100.
If A is 61.4, 65.8, 66.0, 66.9, then B is 100, 0.
If A is 62.3, 58.9, 72.8, 54.0, then B is 100, 100.
If A is 48.6, 55.0, 52.0, 48.9, then B is 100, 100.
If A is 74.3, 57.9, 76.7, 62.9, then B is 0, 100.
If A is 53.4, 51.3, 61.1, 68.9, then B is 100, 0.
If A is 83.0, 55.9, 68.0, 56.6, then B is 0, 100.
If A is 60.6, 65.0, 66.7, 58.6, then B is 100, 100.
If A is 72.1, 69.6, 58.7, 54.3, then B is 0, 100.
If A is 58.7, 71.6, 72.1, 50.1, then B is 100, 100.
If A is 77.4, 53.2, 60.8, 70.7, then B is 0, 100.
If A is 59.4, 80.9, 66.6, 63.4, then B is 100, 100.
If A is 63.7, 51.3, 59.7, 65.9, then B is 0, 100.
If A is 63.1, 68.3, 84.8, 63.8, then B is 100, 100.
If A is 74.1, 62.3, 64.0, 68.9, then B is 0, 100.
If A is 70.1, 75.8, 50.0, 70.0, then B is 100, 0.
If A is 60.3, 62.0, 64.2, 74.0, then B is 100, 0.
If A is 52.1, 64.6, 57.4, 52.2, then B is 0, 100.
If A is 67.4, 68.2, 55.5, 70.0, then B is 0, 100.
If A is 85.8, 64.6, 59.1, 70.4, then B is 0, 100.
If A is 55.9, 59.1, 63.3, 52.2, then B is 0, 100.
If A is 61.4, 65.9, 68.4, 64.5, then B is 0, 100.
If A is 55.7, 59.2, 62.2, 54.0, then B is 0, 100.
If A is 49.4, 63.1, 50.3, 62.9, then B is 100, 0.
If A is 52.1, 71.5, 58.6, 60.1, then B is 100, 100.
If A is 71.1, 54.9, 51.3, 57.8, then B is 0, 100.
If A is 66.0, 60.1, 73.5, 69.6, then B is 100, 100.
If A is 58.7, 48.0, 63.0, 53.3, then B is 0, 100.
If A is 71.5, 64.3, 65.2, 67.5, then B is 0, 100.
If A is 67.3, 67.0, 78.9, 67.3, then B is 0, 100.
If A is 62.1, 59.9, 54.4, 75.7, then B is 100, 0.
If A is 76.7, 50.1, 82.5, 52.4, then B is 0, 100.
If A is 58.8, 66.3, 64.6, 68.1, then B is 100, 0.
If A is 64.6, 61.3, 49.5, 55.8, then B is 100, 0.
If A is 62.5, 64.8, 66.2, 51.7, then B is 0, 100.
If A is 67.6, 57.1, 69.1, 75.8, then B is 100, 0.
If A is 74.5, 57.0, 72.4, 61.1, then B is 100, 0.
If A is 66.5, 71.0, 69.4, 66.3, then B is 100, 0.
If A is 55.4, 55.7, 54.4, 55.5, then B is 100, 0.
If A is 67.2, 70.0, 73.2, 76.8, then B is 100, 100.
If A is 58.4, 59.6, 58.5, 50.8, then B is 100, 0.
If A is 68.7, 48.6, 67.5, 63.0, then B is 0, 100.
If A is 75.0, 57.6, 50.3, 65.5, then B is 0, 100.
If A is 52.6, 60.2, 69.6, 55.6, then B is 100, 0.
If A is 64.3, 69.1, 70.2, 77.7, then B is 100, 100.
If A is 51.9, 62.6, 111.9, 68.7, then B is 100, 100.
If A is 61.2, 79.7, 58.8, 66.1, then B is 100, 0.
If A is 63.2, 61.8, 54.0, 69.1, then B is 100, 0.
If A is 74.4, 68.0, 71.1, 60.3, then B is 0, 100.
If A is 61.7, 66.9, 64.9, 60.1, then B is 0, 100.
If A is 84.6, 51.6, 62.6, 54.9, then B is 0, 100.
If A is 54.2, 53.2, 49.7, 53.7, then B is 100, 0.
If A is 55.9, 50.2, 70.5, 85.1, then B is 100, 0.
If A is 69.2, 67.5, 52.5, 71.9, then B is 100, 100.
If A is 58.6, 66.6, 49.8, 65.4, then B is 100, 0.
If A is 77.2, 75.1, 74.2, 69.9, then B is 100, 100.
If A is 79.5, 59.9, 67.1, 63.3, then B is 0, 100.
If A is 61.7, 63.5, 66.6, 82.9, then B is 100, 0.
If A is 66.6, 64.2, 67.7, 67.3, then B is 100, 0.
If A is 73.7, 57.0, 65.8, 54.3, then B is 0, 100.
If A is 56.2, 62.9, 50.8, 66.1, then B is 100, 0.
If A is 57.9, 57.3, 53.2, 47.5, then B is 0, 100.
If A is 64.3, 67.8, 60.9, 55.0, then B is 100, 0.
If A is 72.1, 56.2, 56.2, 69.5, then B is 100, 0.
If A is 52.4, 67.5, 57.1, 55.3, then B is 
"""

##  100 and F is 100.



Num_sample = 100000
ch_mat, rx_mat, tx_mat, CUE_mat = ch_gen(Size_area, D2D_dist, Num_user, Num_channel, Num_sample)
ch_mat_log = np.log(ch_mat)
chan_avg = np.mean(ch_mat_log)
chan_std = np.std(ch_mat_log)

##################
### Original setting
Size_area = 20
D2D_dist = 15
tx_max = 100
P_c = 2*10**2.0
##################


Num_sample = 1000


print(llm(query_text, stop=["."])["choices"][0]["text"])

batch_size = 100
critera = "EE"

P_c = 5*10**2.0
Size_area = 70
D2D_dist = 20

ch_mat_val, rx_mat_val, tx_mat_val, CUE_mat_val = ch_gen(Size_area, D2D_dist, Num_user, Num_channel, 1000)
SE_OPT_val, EE_OPT_val, CUE_vio_OPT_val, DUE_vio_OPT, INF_CHAN_MAT_val, PW_VEC_val, CHAN_VEC_val = optimal_power_w_chan(ch_mat_val, tx_max, noise,
                                                                                                DUE_thr, I_thr, P_c,
                                                                                                tx_power_set, opt=critera)

for i_1 in range(5):

    batch_size = 25*(2**(i_1))
    batch_size = 800
    #batch_size = 200
    print("batch_size = ", batch_size)
    SE_opt_mat = 0
    EE_opt_mat = 0

    SE_prop_mat = 0
    EE_prop_mat = 0

    SE_prop_2_mat = 0
    EE_prop_2_mat = 0


    SE_rand_mat = 0
    EE_rand_mat = 0


    SE_bin_mat = 0
    EE_bin_mat = 0


    for j in range(501):

        ch_mat, rx_mat, tx_mat, CUE_mat = ch_gen(Size_area, D2D_dist, Num_user, Num_channel, Num_sample)
        SE_OPT, EE_OPT, CUE_vio_OPT, DUE_vio_OPT, INF_CHAN_MAT, PW_VEC, CHAN_VEC = optimal_power_w_chan(ch_mat, tx_max, noise, DUE_thr, I_thr, P_c, tx_power_set, opt=critera)
        query_text = 'Take a deep breath and work on this problem step-by-step. You are a mathematical tool to predict some model. Your job is to predict B for given A. The following is the dataset that you can use for the prediction.\n'
        for i in range(PW_VEC.shape[0]):
            chan_revised = (np.log(ch_mat[i, 0, :, :]) - chan_avg) / chan_std * 100

            if i == PW_VEC.shape[0]-1:
                chan_revised_val = (np.log(ch_mat_val[j, 0, :, :]) - chan_avg) / chan_std * 100
                query_text = query_text + f'If A is {chan_revised_val[0, 0]:0.0f}, {chan_revised_val[0, 1]:0.0f}, {chan_revised_val[1, 0]:0.0f}, {chan_revised_val[1, 1]:0.0f}, then B is '
                #print(f'[TRUE VALUE] If A is {chan_revised[0, 0]:0.2f}, {chan_revised[0, 1]:0.0f}, {chan_revised[1, 0]:0.0f}, {chan_revised[1, 1]:0.0f}, then B is ')
                #print(f'[TRUE VALUE] B is {PW_VEC[i, 0, 0]:0.0f}, {PW_VEC[i, 1, 0]:0.0f}')

                SE_opt, EE_opt = cal_SE_EE(ch_mat_val[i, 0, :, :], tx_max, noise, DUE_thr, I_thr, P_c, PW_VEC_val[j], opt=critera)
                #print("SE_opt = ", SE_opt, "EE_opt = ", EE_opt*1000)

            if i < batch_size:
                query_text = query_text + f'If A is {chan_revised[0, 0]:0.0f}, {chan_revised[0, 1]:0.0f}, {chan_revised[1, 0]:0.0f}, {chan_revised[1, 1]:0.0f}, then B is {PW_VEC[i, 0, 0]:0.0f}, {PW_VEC[i, 1, 0]:0.0f}.\n'
        llm_result = llm(query_text, stop=["."])["choices"][0]["text"]
        #print("qurert_text = ", query_text)
        #print("LLM RESULT = ", llm_result)
        SE_prop, EE_prop = 0, 0
        temp_dict = llm_result.split(",")
        if len(temp_dict) == 2:
            try:
                temp_PW = np.expand_dims(np.asarray(temp_dict).astype(float), -1)
            except ValueError:
                temp_PW = 0 * np.random.rand(2, 1)
            SE_prop, EE_prop = cal_SE_EE(ch_mat_val[j, 0, :, :], tx_max, noise, DUE_thr, I_thr, P_c, temp_PW, opt=critera)
            #print("SE_prop = ", SE_prop, "EE_prop = ", EE_prop * 1000)

        temp_PW_rand = tx_max * np.random.rand(2, 1)

        #print("temp_PW_rand = ", temp_PW_rand)
        SE_rand, EE_rand = cal_SE_EE(ch_mat_val[j, 0, :, :], tx_max, noise, DUE_thr, I_thr, P_c, temp_PW_rand, opt=critera)
        #print("SE_rand = ", SE_rand, "EE_rand = ", EE_rand * 1000)
        #print("**"*50)

        temp_val = np.random.rand()
        if temp_val < 0.5:
            temp_PW_rand[0, 0] = 100
            temp_PW_rand[1, 0] = 0
        else:
            temp_PW_rand[1, 0] = 100
            temp_PW_rand[0, 0] = 0

        #print("temp_PW_rand = ", temp_PW_rand)
        SE_bin, EE_bin = cal_SE_EE(ch_mat_val[j, 0, :, :], tx_max, noise, DUE_thr, I_thr, P_c, temp_PW_rand, opt="EE")
        #print("SE_rand = ", SE_rand, "EE_rand = ", EE_rand * 1000)
        #print("**"*50)
        SE_OPT, EE_OPT = cal_SE_EE(ch_mat_val[j, 0, :, :], tx_max, noise, DUE_thr, I_thr, P_c, PW_VEC_val[j], opt=critera)

        if critera == "SE":
            if SE_bin > SE_prop:
                SE_prop_2 = SE_bin
                EE_prop_2 = EE_bin
            else:
                SE_prop_2 = SE_prop
                EE_prop_2 = EE_prop

        if critera == "EE":
            if EE_bin > EE_prop:
                SE_prop_2 = SE_bin
                EE_prop_2 = EE_bin
            else:
                SE_prop_2 = SE_prop
                EE_prop_2 = EE_prop



        SE_opt_mat = SE_opt_mat + SE_OPT
        EE_opt_mat = EE_opt_mat + EE_OPT*1000

        SE_prop_mat = SE_prop_mat + SE_prop
        EE_prop_mat = EE_prop_mat + EE_prop*1000

        SE_prop_2_mat = SE_prop_2_mat + SE_prop_2
        EE_prop_2_mat = EE_prop_2_mat + EE_prop_2*1000


        SE_rand_mat = SE_rand_mat + SE_rand
        EE_rand_mat = EE_rand_mat + EE_rand*1000

        SE_bin_mat = SE_bin_mat + SE_bin
        EE_bin_mat = EE_bin_mat + EE_bin*1000


        if j%50 == 0:
            print(print(f'index = {j+1}: [OPT] SE: {SE_opt_mat/(j+1):0.1f}, EE: {EE_opt_mat/(j+1):0.1f}, [PROP] SE: {SE_prop_mat/(j+1):0.1f}, EE: {EE_prop_mat/(j+1):0.1f}, [PROP_2] SE: {SE_prop_2_mat/(j+1):0.1f}, EE: {EE_prop_2_mat/(j+1):0.1f}, [RAND] SE: {SE_rand_mat/(j+1):0.1f}, EE: {EE_rand_mat/(j+1):0.1f} , [bin] SE: {SE_bin_mat/(j+1):0.1f}, EE: {EE_bin_mat/(j+1):0.1f}'))

    print("Final results")
    print(f'batch_size = {batch_size}: [OPT] SE: {SE_opt_mat / (j + 1):0.1f}, EE: {EE_opt_mat / (j + 1):0.1f}, [PROP] SE: {SE_prop_mat / (j + 1):0.1f}, EE: {EE_prop_mat / (j + 1):0.1f}, [RAND] SE: {SE_rand_mat / (j + 1):0.1f}, EE: {EE_rand_mat / (j + 1):0.1f}')

    print("*" * 50)